{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voice_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AkFmsPQMvcF"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from numpy import argmax\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import librosa\r\n",
        "import librosa.display\r\n",
        "import IPython.display\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "import pathlib\r\n",
        "import csv\r\n",
        "# sklearn Preprocessing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "#Keras\r\n",
        "import keras\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "from keras import layers\r\n",
        "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.optimizers import SGD\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkIPZ1-On4CU"
      },
      "source": [
        "Collab için drive işlemleri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PXPS-FAQKgy",
        "outputId": "68013b9d-704d-4e95-8773-2c0eb1a9f975"
      },
      "source": [
        "#drive tanımlaması yapılmak zorunda\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N70bIP60UADe",
        "outputId": "ce7ba8df-53a8-4199-9dd0-9f4a4cc31f2b"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7ZM9Zhhotyi"
      },
      "source": [
        " Her ses işlenip spectrogramları png olarak kaydediyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "7Je7GMgPNKLu",
        "outputId": "aa2fb4e0-8569-4e4e-a4cc-0e5eb54cfd20"
      },
      "source": [
        "\r\n",
        "words=['down', 'eat', 'sleep', 'up']\r\n",
        "\r\n",
        "current_path = \"drive/My Drive/training_sets/\"\r\n",
        " \r\n",
        "for i in range (len(words)):\r\n",
        "  pathlib.Path(f'img_data2/{words[i]}').mkdir(parents=True, exist_ok=True) #for images                           \r\n",
        "  for j in range (10):\r\n",
        "    path = current_path +  words[i] + \"-\" + str(j+1) + \".wav\"  \r\n",
        "    y, sr = librosa.load(path, mono=True, duration=5)\r\n",
        "    plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, sides='default', mode='default', scale='dB');\r\n",
        "    plt.axis('off');\r\n",
        "    plt.savefig((f'img_data2/{words[i]}/{words[i]}-{j+1}.png'))    #Kaydet\r\n",
        "    plt.clf()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr3esoNf-8lK",
        "outputId": "681b4256-c659-4b07-d682-6f19d95fb546"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_2xTwaUQv27",
        "outputId": "ae5bc8e5-233e-4c3f-e9b0-df8c2ecd2fd8"
      },
      "source": [
        "#For  dataset\r\n",
        "import splitfolders \r\n",
        "\r\n",
        "splitfolders.ratio('./img_data2/', output=\"./data2\", seed=1337, ratio=(.8, .2)) # default values\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator( #(X_train , y_train return)\r\n",
        "        rescale=1./255,       # all our pixel values are in range (0,1)\r\n",
        "        shear_range=0.2,      #to apply some random tranfromations\r\n",
        "        zoom_range=0.2,       \r\n",
        "        horizontal_flip=True) \r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator( #(X_test , y_test return)\r\n",
        "        rescale=1./255,       # all our pixel values are in range (0,1)\r\n",
        "        shear_range=0.2,      #to apply some random tranfromations\r\n",
        "        zoom_range=0.2,      \r\n",
        "        horizontal_flip=True) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 40 files [00:00, 5219.56 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAbCnHsWQ0x8",
        "outputId": "81e81b19-9d2a-4ab1-eac0-2b3b22a6bc73"
      },
      "source": [
        "#data generators\r\n",
        "\r\n",
        "#class-mode -> yapılacak sınıflandırmaya göre uygun olanı seçilmelidir. (binary - categorical)     \r\n",
        "training_set = train_datagen.flow_from_directory( \r\n",
        "    './data2/train',\r\n",
        "    target_size=(64, 64),\r\n",
        "    batch_size=1,\r\n",
        "    class_mode='binary',\r\n",
        "    shuffle = False)\r\n",
        "\r\n",
        "test_set = test_datagen.flow_from_directory(\r\n",
        "    './data2/val',\r\n",
        "    target_size=(64, 64),\r\n",
        "    batch_size=1,\r\n",
        "    class_mode='binary',\r\n",
        "    shuffle = False )\r\n",
        "\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 32 images belonging to 4 classes.\n",
            "Found 8 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b244XWauQ30n",
        "outputId": "2cd7f48d-c478-4636-d499-0b3d4c3a9efb"
      },
      "source": [
        "model = Sequential()\r\n",
        "input_shape=(64, 64, 3)                                              #1st hidden layer\r\n",
        "model.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\r\n",
        "model.add(AveragePooling2D((2, 2), strides=(2,2)))\r\n",
        "model.add(Activation('relu'))                                         #2nd hidden layer\r\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\r\n",
        "model.add(AveragePooling2D((2, 2), strides=(2,2)))\r\n",
        "model.add(Activation('relu'))                                         #3rd hidden layer\r\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\r\n",
        "model.add(AveragePooling2D((2, 2), strides=(2,2)))\r\n",
        "model.add(Activation('relu'))                                         #Flatten\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dropout(rate=0.5))                                          #Add fully connected layer.\r\n",
        "model.add(Dense(64))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dropout(rate=0.5))                                          #Output layer\r\n",
        "model.add(Dense(10))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 31, 31, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 93,898\n",
            "Trainable params: 93,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNqVIfJbQ6VW"
      },
      "source": [
        "epochs = 200\r\n",
        "batch_size = 8\r\n",
        "learning_rate = 0.01\r\n",
        "decay_rate = learning_rate / epochs\r\n",
        "momentum = 0.9\r\n",
        "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\r\n",
        "model.compile(optimizer=\"sgd\",  loss =\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgQINX4AQ9GI",
        "outputId": "ebc8f1a2-20de-408d-a7ce-03a0f56aad1a"
      },
      "source": [
        "model.fit_generator(\r\n",
        "        training_set,\r\n",
        "        steps_per_epoch= len(training_set), \r\n",
        "        epochs=200,\r\n",
        "        validation_data=test_set,\r\n",
        "        validation_steps= len(test_set), \r\n",
        "         )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.3358 - accuracy: 0.2812 - val_loss: 1.2137 - val_accuracy: 0.3750\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3993 - accuracy: 0.4375 - val_loss: 1.2507 - val_accuracy: 0.2500\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3068 - accuracy: 0.4062 - val_loss: 1.1554 - val_accuracy: 0.3750\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3012 - accuracy: 0.4375 - val_loss: 1.1454 - val_accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3086 - accuracy: 0.4062 - val_loss: 1.0844 - val_accuracy: 0.5000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2550 - accuracy: 0.3750 - val_loss: 1.1118 - val_accuracy: 0.5000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1736 - accuracy: 0.3750 - val_loss: 1.0435 - val_accuracy: 0.5000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9980 - accuracy: 0.5312 - val_loss: 0.9535 - val_accuracy: 0.5000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2092 - accuracy: 0.4375 - val_loss: 0.9082 - val_accuracy: 0.5000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0238 - accuracy: 0.5000 - val_loss: 1.2798 - val_accuracy: 0.3750\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0974 - accuracy: 0.4062 - val_loss: 0.9680 - val_accuracy: 0.5000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1498 - accuracy: 0.3438 - val_loss: 0.9135 - val_accuracy: 0.7500\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1337 - accuracy: 0.3750 - val_loss: 0.8602 - val_accuracy: 0.5000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0122 - accuracy: 0.5312 - val_loss: 0.7944 - val_accuracy: 0.6250\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9653 - accuracy: 0.5000 - val_loss: 0.7656 - val_accuracy: 0.3750\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8981 - accuracy: 0.5312 - val_loss: 0.8475 - val_accuracy: 0.5000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1274 - accuracy: 0.4375 - val_loss: 0.7931 - val_accuracy: 0.5000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.9361 - accuracy: 0.4062 - val_loss: 0.7660 - val_accuracy: 0.5000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9224 - accuracy: 0.5000 - val_loss: 0.7316 - val_accuracy: 0.5000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8446 - accuracy: 0.5938 - val_loss: 0.7515 - val_accuracy: 0.7500\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8065 - accuracy: 0.5625 - val_loss: 0.7885 - val_accuracy: 0.5000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8589 - accuracy: 0.5625 - val_loss: 0.7202 - val_accuracy: 0.6250\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9794 - accuracy: 0.4688 - val_loss: 0.6888 - val_accuracy: 0.8750\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7792 - accuracy: 0.6250 - val_loss: 0.7213 - val_accuracy: 0.5000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7154 - accuracy: 0.6250 - val_loss: 0.7503 - val_accuracy: 0.6250\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.9848 - accuracy: 0.3750 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7262 - accuracy: 0.6562 - val_loss: 0.9156 - val_accuracy: 0.3750\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8941 - accuracy: 0.5000 - val_loss: 0.6425 - val_accuracy: 0.7500\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7095 - accuracy: 0.5938 - val_loss: 0.6188 - val_accuracy: 0.6250\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8338 - accuracy: 0.5938 - val_loss: 0.6836 - val_accuracy: 0.5000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9393 - accuracy: 0.5625 - val_loss: 0.6560 - val_accuracy: 0.6250\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6976 - accuracy: 0.6875 - val_loss: 0.6506 - val_accuracy: 0.6250\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8268 - accuracy: 0.5312 - val_loss: 0.6384 - val_accuracy: 0.7500\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8435 - accuracy: 0.4375 - val_loss: 0.7038 - val_accuracy: 0.7500\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7704 - accuracy: 0.5625 - val_loss: 0.5451 - val_accuracy: 0.8750\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7840 - accuracy: 0.4688 - val_loss: 0.6291 - val_accuracy: 0.7500\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7065 - accuracy: 0.6562 - val_loss: 0.6010 - val_accuracy: 0.6250\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7603 - accuracy: 0.5938 - val_loss: 0.5643 - val_accuracy: 0.8750\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5884 - accuracy: 0.7500 - val_loss: 0.5914 - val_accuracy: 0.7500\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7607 - accuracy: 0.6875 - val_loss: 0.5066 - val_accuracy: 0.8750\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7432 - accuracy: 0.5312 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.6875 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6275 - accuracy: 0.7500 - val_loss: 0.4685 - val_accuracy: 0.8750\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.8438 - val_loss: 0.4744 - val_accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7218 - accuracy: 0.6562 - val_loss: 0.5376 - val_accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7101 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.8750\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8111 - accuracy: 0.5625 - val_loss: 0.5372 - val_accuracy: 0.6250\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6542 - accuracy: 0.6875 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7043 - accuracy: 0.6562 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6255 - accuracy: 0.7500 - val_loss: 0.4323 - val_accuracy: 0.7500\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7236 - accuracy: 0.5312 - val_loss: 0.4683 - val_accuracy: 0.7500\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0394 - accuracy: 0.5000 - val_loss: 0.8376 - val_accuracy: 0.7500\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8600 - accuracy: 0.6875 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.7500 - val_loss: 0.4316 - val_accuracy: 0.7500\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.6534 - accuracy: 0.7188 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5492 - accuracy: 0.8125 - val_loss: 0.4698 - val_accuracy: 0.6250\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5570 - accuracy: 0.7188 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6500 - accuracy: 0.7188 - val_loss: 0.3257 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6952 - accuracy: 0.7500 - val_loss: 0.4152 - val_accuracy: 0.7500\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7027 - accuracy: 0.6562 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6671 - accuracy: 0.6562 - val_loss: 0.4642 - val_accuracy: 0.7500\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5886 - accuracy: 0.7500 - val_loss: 0.4435 - val_accuracy: 0.7500\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5686 - accuracy: 0.7500 - val_loss: 0.4480 - val_accuracy: 0.7500\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7100 - accuracy: 0.7500 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6210 - accuracy: 0.7500 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4639 - accuracy: 0.8125 - val_loss: 0.4145 - val_accuracy: 0.7500\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5845 - accuracy: 0.6875 - val_loss: 0.3712 - val_accuracy: 0.7500\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4833 - accuracy: 0.7500 - val_loss: 0.4369 - val_accuracy: 0.7500\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.8438 - val_loss: 0.3748 - val_accuracy: 0.7500\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5923 - accuracy: 0.7812 - val_loss: 0.4158 - val_accuracy: 0.7500\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7044 - accuracy: 0.5625 - val_loss: 0.4304 - val_accuracy: 0.7500\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6168 - accuracy: 0.7812 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5811 - accuracy: 0.7188 - val_loss: 0.3608 - val_accuracy: 0.7500\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5157 - accuracy: 0.7188 - val_loss: 0.3420 - val_accuracy: 0.8750\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6242 - accuracy: 0.5938 - val_loss: 0.3394 - val_accuracy: 0.8750\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3843 - accuracy: 0.8438 - val_loss: 0.4676 - val_accuracy: 0.7500\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.7188 - val_loss: 0.3176 - val_accuracy: 0.8750\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5087 - accuracy: 0.7188 - val_loss: 0.3517 - val_accuracy: 0.7500\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4963 - accuracy: 0.7500 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5386 - accuracy: 0.7500 - val_loss: 0.3498 - val_accuracy: 0.8750\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4741 - accuracy: 0.7188 - val_loss: 0.3377 - val_accuracy: 0.8750\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5140 - accuracy: 0.7812 - val_loss: 0.3550 - val_accuracy: 0.8750\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5127 - accuracy: 0.7500 - val_loss: 0.3922 - val_accuracy: 0.7500\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5898 - accuracy: 0.6562 - val_loss: 0.4242 - val_accuracy: 0.7500\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.5288 - accuracy: 0.8125 - val_loss: 0.5749 - val_accuracy: 0.7500\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.8125 - val_loss: 0.4461 - val_accuracy: 0.6250\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4778 - accuracy: 0.7500 - val_loss: 0.3653 - val_accuracy: 0.7500\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5322 - accuracy: 0.7500 - val_loss: 0.3410 - val_accuracy: 0.7500\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6550 - accuracy: 0.6562 - val_loss: 0.3763 - val_accuracy: 0.7500\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5476 - accuracy: 0.7188 - val_loss: 0.3553 - val_accuracy: 0.8750\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.9062 - val_loss: 0.2959 - val_accuracy: 0.8750\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5131 - accuracy: 0.7188 - val_loss: 0.3878 - val_accuracy: 0.8750\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5909 - accuracy: 0.6875 - val_loss: 0.3819 - val_accuracy: 0.7500\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4592 - accuracy: 0.8125 - val_loss: 0.5875 - val_accuracy: 0.6250\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5136 - accuracy: 0.8125 - val_loss: 0.3461 - val_accuracy: 0.8750\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5308 - accuracy: 0.8438 - val_loss: 0.3507 - val_accuracy: 0.7500\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5798 - accuracy: 0.7500 - val_loss: 0.3496 - val_accuracy: 0.7500\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.8125 - val_loss: 0.3498 - val_accuracy: 0.7500\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 0.7812 - val_loss: 0.3317 - val_accuracy: 0.8750\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.8438 - val_loss: 0.4192 - val_accuracy: 0.7500\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.8438 - val_loss: 0.4522 - val_accuracy: 0.7500\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5400 - accuracy: 0.7188 - val_loss: 0.3778 - val_accuracy: 0.8750\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.8125 - val_loss: 0.2914 - val_accuracy: 0.8750\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.4019 - val_accuracy: 0.7500\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5202 - accuracy: 0.7500 - val_loss: 0.3121 - val_accuracy: 0.8750\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5180 - accuracy: 0.7500 - val_loss: 0.3503 - val_accuracy: 0.7500\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8438 - val_loss: 0.3290 - val_accuracy: 0.8750\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5781 - accuracy: 0.7188 - val_loss: 0.4908 - val_accuracy: 0.7500\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4807 - accuracy: 0.7812 - val_loss: 0.3798 - val_accuracy: 0.7500\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6136 - accuracy: 0.7188 - val_loss: 0.4724 - val_accuracy: 0.7500\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5292 - accuracy: 0.7812 - val_loss: 0.3600 - val_accuracy: 0.8750\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4135 - accuracy: 0.8125 - val_loss: 0.3220 - val_accuracy: 0.7500\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5107 - accuracy: 0.6875 - val_loss: 0.4192 - val_accuracy: 0.7500\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.3824 - accuracy: 0.7812 - val_loss: 0.3195 - val_accuracy: 0.8750\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5572 - accuracy: 0.7188 - val_loss: 0.4261 - val_accuracy: 0.7500\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4525 - accuracy: 0.8125 - val_loss: 0.3376 - val_accuracy: 0.8750\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5061 - accuracy: 0.6562 - val_loss: 0.3753 - val_accuracy: 0.8750\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5688 - accuracy: 0.7500 - val_loss: 0.2991 - val_accuracy: 0.8750\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5985 - accuracy: 0.7500 - val_loss: 0.3827 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.3682 - val_accuracy: 0.7500\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3757 - accuracy: 0.7812 - val_loss: 0.3402 - val_accuracy: 0.8750\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.6181 - val_accuracy: 0.7500\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6473 - accuracy: 0.7188 - val_loss: 0.4453 - val_accuracy: 0.8750\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5051 - accuracy: 0.7500 - val_loss: 0.3335 - val_accuracy: 0.8750\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3952 - accuracy: 0.7812 - val_loss: 0.3748 - val_accuracy: 0.8750\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.3186 - val_accuracy: 0.8750\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.7188 - val_loss: 0.3765 - val_accuracy: 0.7500\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3684 - accuracy: 0.8125 - val_loss: 0.3137 - val_accuracy: 0.6250\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: 0.3721 - val_accuracy: 0.7500\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2904 - accuracy: 0.9062 - val_loss: 0.3248 - val_accuracy: 0.8750\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4132 - accuracy: 0.8125 - val_loss: 0.3512 - val_accuracy: 0.8750\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5522 - accuracy: 0.7500 - val_loss: 0.4276 - val_accuracy: 0.7500\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5767 - accuracy: 0.6875 - val_loss: 0.3200 - val_accuracy: 0.7500\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4445 - accuracy: 0.8125 - val_loss: 0.3323 - val_accuracy: 0.8750\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4650 - accuracy: 0.7500 - val_loss: 0.3675 - val_accuracy: 0.7500\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4178 - accuracy: 0.7812 - val_loss: 0.3281 - val_accuracy: 0.8750\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4642 - accuracy: 0.8438 - val_loss: 0.3182 - val_accuracy: 0.8750\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8750 - val_loss: 0.3622 - val_accuracy: 0.7500\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.3287 - val_accuracy: 0.6250\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3286 - accuracy: 0.8438 - val_loss: 0.4264 - val_accuracy: 0.7500\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2698 - accuracy: 0.9062 - val_loss: 0.3275 - val_accuracy: 0.7500\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3621 - accuracy: 0.8438 - val_loss: 0.3795 - val_accuracy: 0.7500\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.2698 - accuracy: 0.8438 - val_loss: 0.2610 - val_accuracy: 0.8750\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3599 - accuracy: 0.8125 - val_loss: 0.3078 - val_accuracy: 0.8750\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4615 - accuracy: 0.8750 - val_loss: 0.3177 - val_accuracy: 0.7500\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2769 - accuracy: 0.9062 - val_loss: 0.3460 - val_accuracy: 0.7500\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2377 - accuracy: 0.9062 - val_loss: 0.3212 - val_accuracy: 0.8750\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3585 - accuracy: 0.8438 - val_loss: 0.2831 - val_accuracy: 0.8750\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5958 - accuracy: 0.7500 - val_loss: 0.5813 - val_accuracy: 0.5000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.3750 - val_accuracy: 0.7500\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4917 - accuracy: 0.7500 - val_loss: 0.2794 - val_accuracy: 0.8750\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2777 - accuracy: 0.8125 - val_loss: 0.3166 - val_accuracy: 0.8750\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3780 - accuracy: 0.8438 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4475 - accuracy: 0.7812 - val_loss: 0.3744 - val_accuracy: 0.7500\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3134 - accuracy: 0.8125 - val_loss: 0.2914 - val_accuracy: 0.8750\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4864 - accuracy: 0.8438 - val_loss: 0.3312 - val_accuracy: 0.8750\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2376 - accuracy: 0.9062 - val_loss: 0.3505 - val_accuracy: 0.8750\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5260 - accuracy: 0.7812 - val_loss: 0.3625 - val_accuracy: 0.8750\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2771 - accuracy: 0.9062 - val_loss: 0.2303 - val_accuracy: 0.8750\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4122 - accuracy: 0.7812 - val_loss: 0.2292 - val_accuracy: 0.8750\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6651 - accuracy: 0.7812 - val_loss: 0.3391 - val_accuracy: 0.8750\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3099 - accuracy: 0.8438 - val_loss: 0.3767 - val_accuracy: 0.7500\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1883 - accuracy: 0.9688 - val_loss: 0.2821 - val_accuracy: 0.8750\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2455 - accuracy: 0.8438 - val_loss: 0.4784 - val_accuracy: 0.7500\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8438 - val_loss: 0.3881 - val_accuracy: 0.6250\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4068 - accuracy: 0.7812 - val_loss: 0.3718 - val_accuracy: 0.8750\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.9062 - val_loss: 0.2850 - val_accuracy: 0.7500\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5377 - accuracy: 0.7500 - val_loss: 0.2985 - val_accuracy: 0.8750\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3757 - accuracy: 0.8125 - val_loss: 0.3755 - val_accuracy: 0.7500\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5503 - accuracy: 0.8438 - val_loss: 0.3111 - val_accuracy: 0.8750\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.4315 - val_accuracy: 0.7500\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.8750 - val_loss: 0.2640 - val_accuracy: 0.8750\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.3506 - accuracy: 0.8750 - val_loss: 0.3650 - val_accuracy: 0.7500\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2893 - accuracy: 0.9375 - val_loss: 0.2752 - val_accuracy: 0.7500\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4403 - accuracy: 0.8438 - val_loss: 0.2960 - val_accuracy: 0.7500\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3257 - accuracy: 0.8125 - val_loss: 0.3196 - val_accuracy: 0.7500\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4648 - accuracy: 0.7500 - val_loss: 0.3072 - val_accuracy: 0.8750\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2896 - accuracy: 0.8125 - val_loss: 0.3546 - val_accuracy: 0.8750\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3161 - accuracy: 0.8750 - val_loss: 0.2331 - val_accuracy: 0.8750\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3533 - accuracy: 0.8438 - val_loss: 0.3590 - val_accuracy: 0.7500\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3297 - accuracy: 0.8438 - val_loss: 0.4006 - val_accuracy: 0.7500\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5600 - accuracy: 0.7812 - val_loss: 0.4495 - val_accuracy: 0.6250\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3640 - accuracy: 0.7812 - val_loss: 0.3280 - val_accuracy: 0.7500\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4208 - accuracy: 0.8125 - val_loss: 0.4067 - val_accuracy: 0.7500\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3219 - accuracy: 0.7812 - val_loss: 0.3519 - val_accuracy: 0.7500\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2855 - accuracy: 0.9062 - val_loss: 0.3877 - val_accuracy: 0.6250\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3250 - accuracy: 0.9062 - val_loss: 0.2901 - val_accuracy: 0.8750\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3306 - accuracy: 0.8125 - val_loss: 0.2705 - val_accuracy: 0.8750\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3256 - accuracy: 0.8438 - val_loss: 0.3312 - val_accuracy: 0.7500\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5566 - accuracy: 0.7500 - val_loss: 0.2808 - val_accuracy: 0.8750\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4202 - accuracy: 0.7812 - val_loss: 0.2569 - val_accuracy: 0.8750\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8438 - val_loss: 0.2680 - val_accuracy: 0.8750\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3135 - accuracy: 0.8750 - val_loss: 0.2519 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3001 - accuracy: 0.8438 - val_loss: 0.2630 - val_accuracy: 0.7500\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5631 - accuracy: 0.7500 - val_loss: 0.2479 - val_accuracy: 0.8750\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4821 - accuracy: 0.7500 - val_loss: 0.3440 - val_accuracy: 0.8750\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3806 - accuracy: 0.7812 - val_loss: 0.2856 - val_accuracy: 0.7500\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.2940 - accuracy: 0.8438 - val_loss: 0.3048 - val_accuracy: 0.7500\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3618 - accuracy: 0.8125 - val_loss: 0.2588 - val_accuracy: 0.8750\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8438 - val_loss: 0.2446 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f171c54b6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcoLLlzMRBVM",
        "outputId": "b5e4afa3-2e43-4985-d2ec-516be34017ec"
      },
      "source": [
        "#Model Evaluation\r\n",
        "model.evaluate_generator(generator=test_set, steps=200)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3373205065727234, 0.875]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKVSRpMJRDyH",
        "outputId": "d0dc476b-d338-4d54-dec2-1a2beecf72c2"
      },
      "source": [
        "#test veri setini değiştiriyoruz. Ama önce sıfırlanması gerekiyor\r\n",
        "test_set.reset()\r\n",
        "pred = model.predict_generator(test_set, verbose=1) #steps= len(test_set)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 5ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3FP2cWXRGGL"
      },
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)\r\n",
        "#print(predicted_class_indices)\r\n",
        "\r\n",
        "labels = (training_set.class_indices)\r\n",
        "labels = dict((v,k) for k,v in labels.items())\r\n",
        "predictions = [labels[k] for k in predicted_class_indices]\r\n",
        "predictions = predictions[:600]\r\n",
        "filenames=test_set.filenames\r\n",
        "#print(filenames)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTyuCRKBRI4w",
        "outputId": "89521483-8a3d-455c-9f4d-51b0f0a68ba9"
      },
      "source": [
        "print(len(filenames), len(predictions))\r\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIBkHS1fp725"
      },
      "source": [
        "Karşılaştırmalar için tablo oluşturuldu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rly7xsQRMeS"
      },
      "source": [
        "import csv\r\n",
        "results=pd.DataFrame({\"Filename\" :filenames,\r\n",
        "                      \"Predictions\":predictions})\r\n",
        "\r\n",
        "    \r\n",
        "results.to_csv(\"prediction_results.csv\",index=False)"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}