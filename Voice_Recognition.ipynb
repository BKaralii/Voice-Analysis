{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voice_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AkFmsPQMvcF"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from numpy import argmax\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import librosa\r\n",
        "import librosa.display\r\n",
        "import IPython.display\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "import pathlib\r\n",
        "import csv\r\n",
        "# sklearn Preprocessing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "#Keras\r\n",
        "import keras\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "from keras import layers\r\n",
        "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.optimizers import SGD\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkIPZ1-On4CU"
      },
      "source": [
        "Collab için drive işlemleri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PXPS-FAQKgy",
        "outputId": "eb5bb366-f080-4b10-ebd9-792f621ebe6c"
      },
      "source": [
        "#drive tanımlaması yapılmak zorunda\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N70bIP60UADe",
        "outputId": "b9ed7a62-7ef0-4e41-c2e4-2bedbf4c2d7c"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7ZM9Zhhotyi"
      },
      "source": [
        " Her ses işlenip spectrogramları png olarak kaydediyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Je7GMgPNKLu"
      },
      "source": [
        "\r\n",
        "words=['down', 'eat', 'sleep', 'up']\r\n",
        "\r\n",
        "current_path = \"drive/My Drive/training_sets/\"\r\n",
        " \r\n",
        "for i in range (len(words)):\r\n",
        "  \r\n",
        "  pathlib.Path(f'img_data2/{words[i]}').mkdir(parents=True, exist_ok=True) #for images                           \r\n",
        "  for j in range (10):\r\n",
        "    path = current_path +  words[i] + \"-\" + str(j+1) + \".wav\"  \r\n",
        "    y, sr = librosa.load(path, mono=True, duration=5)\r\n",
        "    print(y.shape)\r\n",
        "    plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, sides='default', mode='default', scale='dB');\r\n",
        "    print(y.shape)\r\n",
        "    plt.axis('off');\r\n",
        "    plt.savefig((f'img_data2/{words[i]}/{words[i]}-{j+1}.png'))    #Kaydet\r\n",
        "    plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT3T5XcpBOsu"
      },
      "source": [
        "---------------------- Another person same word check --------------------------(Optional) ->LOW LEARNİNG ACCURACY "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "lLgfK8FO9WGj",
        "outputId": "2f25fc06-16bb-48a1-99ff-4555f801b22e"
      },
      "source": [
        "#Farklı seste aynı kelimeler analizi icin \r\n",
        "current_path = \"drive/My Drive/test_/\"\r\n",
        "for i in range (len(words)):\r\n",
        "  pathlib.Path(f'test_png/{words[i]}').mkdir(parents=True, exist_ok=True) #for images                           \r\n",
        "  for j in range (10):\r\n",
        "    path = current_path +  words[i] + \"-\" + str(j+1) + \".wav\"\r\n",
        "    y, sr = librosa.load(path, mono=True, duration=5)\r\n",
        "    plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, sides='default', mode='default', scale='dB');\r\n",
        "    plt.axis('off');\r\n",
        "    plt.savefig((f'test_png/{words[i]}/{words[i]}-{j+1}.png'))    #Kaydet\r\n",
        "    plt.clf()\r\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr3esoNf-8lK",
        "outputId": "8b9ec86c-6325-458c-9292-d7ee8c33c12a"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_2xTwaUQv27",
        "outputId": "2e35d0cc-9551-4f75-8710-13083eddaef2"
      },
      "source": [
        "#For  dataset\r\n",
        "import splitfolders \r\n",
        "\r\n",
        "splitfolders.ratio('./img_data2/', output=\"./data2\", seed=1337, ratio=(.8, .2)) # default values\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator( #(X_train , y_train return)\r\n",
        "        rescale=1./255,       # all our pixel values are in range (0,1)\r\n",
        "        shear_range=0.2,      #to apply some random tranfromations\r\n",
        "        zoom_range=0.2,       \r\n",
        "        horizontal_flip=True) \r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator( #(X_test , y_test return)\r\n",
        "        rescale=1./255,       # all our pixel values are in range (0,1)\r\n",
        "        shear_range=0.2,      #to apply some random tranfromations\r\n",
        "        zoom_range=0.2,      \r\n",
        "        horizontal_flip=True) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 40 files [00:00, 5187.92 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAbCnHsWQ0x8",
        "outputId": "2b435451-0f1e-4867-ea3b-9f85859c725d"
      },
      "source": [
        "#data generators\r\n",
        "\r\n",
        "#class-mode -> yapılacak sınıflandırmaya göre uygun olanı seçilmelidir. (binary - categorical)     \r\n",
        "training_set = train_datagen.flow_from_directory( \r\n",
        "    './data2/train',\r\n",
        "    target_size=(64, 64),  ## input size belirlendi.\r\n",
        "    batch_size=1,\r\n",
        "    class_mode='binary',\r\n",
        "    shuffle = False)\r\n",
        "\r\n",
        "test_set = test_datagen.flow_from_directory(\r\n",
        "    './data2/val',   # 'test_png'-> './data2/val' for another people same words\r\n",
        "    target_size=(64, 64),    ## input size belirlendi.\r\n",
        "    batch_size=1,\r\n",
        "    class_mode='binary',\r\n",
        "    shuffle = False )\r\n",
        "\r\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 32 images belonging to 4 classes.\n",
            "Found 8 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b244XWauQ30n",
        "outputId": "48d3d6d6-7546-4736-8504-14a559ffcbd8"
      },
      "source": [
        "model = Sequential()\r\n",
        "input_shape=(64, 64, 3)                                              #1st hidden layer\r\n",
        "model.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\r\n",
        "model.add(AveragePooling2D((2, 2), strides=(2,2)))\r\n",
        "model.add(Activation('relu'))                                         #2nd hidden layer\r\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\r\n",
        "model.add(AveragePooling2D((2, 2), strides=(2,2)))\r\n",
        "model.add(Activation('relu'))                                         #3rd hidden layer\r\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\r\n",
        "model.add(AveragePooling2D((2, 2), strides=(2,2)))\r\n",
        "model.add(Activation('relu'))                                         #Flatten\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dropout(rate=0.5))                                          #Add fully connected layer.\r\n",
        "model.add(Dense(64))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dropout(rate=0.5))                                          #Output layer\r\n",
        "model.add(Dense(10))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 31, 31, 32)        896       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_28 (Averag (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_29 (Averag (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_30 (Averag (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 93,898\n",
            "Trainable params: 93,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNqVIfJbQ6VW"
      },
      "source": [
        "epochs = 200\r\n",
        "batch_size = 8\r\n",
        "learning_rate = 0.01\r\n",
        "decay_rate = learning_rate / epochs\r\n",
        "momentum = 0.9\r\n",
        "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\r\n",
        "model.compile(optimizer=\"sgd\",  loss =\"sparse_categorical_crossentropy\", metrics=['accuracy']) # sgd, adam dan daha basarili "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgQINX4AQ9GI",
        "outputId": "9b4e4734-5938-44dd-a82c-a1801d8da310"
      },
      "source": [
        "model.fit_generator(\r\n",
        "        training_set,\r\n",
        "        steps_per_epoch= len(training_set), \r\n",
        "        epochs=200,\r\n",
        "        validation_data=test_set,\r\n",
        "        validation_steps= len(test_set), \r\n",
        "         )"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "32/32 [==============================] - 1s 12ms/step - loss: 2.2847 - accuracy: 0.1345 - val_loss: 2.0669 - val_accuracy: 0.2500\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9650 - accuracy: 0.2844 - val_loss: 1.7493 - val_accuracy: 0.2500\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.7255 - accuracy: 0.2976 - val_loss: 1.7135 - val_accuracy: 0.2500\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7879 - accuracy: 0.1883 - val_loss: 1.5897 - val_accuracy: 0.2500\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7654 - accuracy: 0.3264 - val_loss: 1.5145 - val_accuracy: 0.2500\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6811 - accuracy: 0.3188 - val_loss: 1.5083 - val_accuracy: 0.2500\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6905 - accuracy: 0.2502 - val_loss: 1.5207 - val_accuracy: 0.2500\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6389 - accuracy: 0.2663 - val_loss: 1.4851 - val_accuracy: 0.2500\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5737 - accuracy: 0.1139 - val_loss: 1.4609 - val_accuracy: 0.2500\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5949 - accuracy: 0.1317 - val_loss: 1.5069 - val_accuracy: 0.3750\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6303 - accuracy: 0.2626 - val_loss: 1.4230 - val_accuracy: 0.2500\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6764 - accuracy: 0.1260 - val_loss: 1.4252 - val_accuracy: 0.2500\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4996 - accuracy: 0.3254 - val_loss: 1.4523 - val_accuracy: 0.2500\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6913 - accuracy: 0.1072 - val_loss: 1.4368 - val_accuracy: 0.2500\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5291 - accuracy: 0.3811 - val_loss: 1.4730 - val_accuracy: 0.2500\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4983 - accuracy: 0.1590 - val_loss: 1.4259 - val_accuracy: 0.2500\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5345 - accuracy: 0.2546 - val_loss: 1.4376 - val_accuracy: 0.2500\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5880 - accuracy: 0.1596 - val_loss: 1.4616 - val_accuracy: 0.2500\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3864 - accuracy: 0.3601 - val_loss: 1.4214 - val_accuracy: 0.2500\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6403 - accuracy: 0.2499 - val_loss: 1.4230 - val_accuracy: 0.2500\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4414 - accuracy: 0.2658 - val_loss: 1.4501 - val_accuracy: 0.2500\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5596 - accuracy: 0.0416 - val_loss: 1.4444 - val_accuracy: 0.2500\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5056 - accuracy: 0.2445 - val_loss: 1.4088 - val_accuracy: 0.2500\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4053 - accuracy: 0.2753 - val_loss: 1.4161 - val_accuracy: 0.2500\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4425 - accuracy: 0.3678 - val_loss: 1.4134 - val_accuracy: 0.2500\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5711 - accuracy: 0.1286 - val_loss: 1.4119 - val_accuracy: 0.2500\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4716 - accuracy: 0.0697 - val_loss: 1.4059 - val_accuracy: 0.2500\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3948 - accuracy: 0.4001 - val_loss: 1.4157 - val_accuracy: 0.2500\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3588 - accuracy: 0.4317 - val_loss: 1.4011 - val_accuracy: 0.2500\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4543 - accuracy: 0.1130 - val_loss: 1.4411 - val_accuracy: 0.2500\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5055 - accuracy: 0.1764 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.5190 - accuracy: 0.2472 - val_loss: 1.4063 - val_accuracy: 0.2500\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4297 - accuracy: 0.4196 - val_loss: 1.4066 - val_accuracy: 0.2500\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4762 - accuracy: 0.1129 - val_loss: 1.4062 - val_accuracy: 0.5000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4801 - accuracy: 0.2568 - val_loss: 1.4062 - val_accuracy: 0.2500\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5000 - accuracy: 0.2950 - val_loss: 1.4066 - val_accuracy: 0.2500\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4851 - accuracy: 0.1629 - val_loss: 1.4126 - val_accuracy: 0.2500\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4864 - accuracy: 0.2460 - val_loss: 1.4162 - val_accuracy: 0.2500\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4881 - accuracy: 0.0965 - val_loss: 1.4141 - val_accuracy: 0.2500\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4891 - accuracy: 0.1632 - val_loss: 1.3931 - val_accuracy: 0.2500\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4355 - accuracy: 0.3617 - val_loss: 1.4036 - val_accuracy: 0.2500\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4269 - accuracy: 0.1850 - val_loss: 1.3918 - val_accuracy: 0.2500\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5155 - accuracy: 0.2037 - val_loss: 1.4188 - val_accuracy: 0.3750\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4468 - accuracy: 0.1923 - val_loss: 1.4076 - val_accuracy: 0.2500\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4019 - accuracy: 0.3357 - val_loss: 1.3944 - val_accuracy: 0.2500\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5180 - accuracy: 0.2207 - val_loss: 1.4013 - val_accuracy: 0.5000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4737 - accuracy: 0.1123 - val_loss: 1.3996 - val_accuracy: 0.2500\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5068 - accuracy: 0.0827 - val_loss: 1.4007 - val_accuracy: 0.2500\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4677 - accuracy: 0.1973 - val_loss: 1.3995 - val_accuracy: 0.2500\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4220 - accuracy: 0.1733 - val_loss: 1.3932 - val_accuracy: 0.2500\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4995 - accuracy: 0.2819 - val_loss: 1.3985 - val_accuracy: 0.2500\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4257 - accuracy: 0.1770 - val_loss: 1.3919 - val_accuracy: 0.2500\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4602 - accuracy: 0.2505 - val_loss: 1.3836 - val_accuracy: 0.5000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4306 - accuracy: 0.2598 - val_loss: 1.4013 - val_accuracy: 0.2500\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4412 - accuracy: 0.2056 - val_loss: 1.3887 - val_accuracy: 0.3750\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4756 - accuracy: 0.1824 - val_loss: 1.3907 - val_accuracy: 0.3750\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4616 - accuracy: 0.2092 - val_loss: 1.3822 - val_accuracy: 0.5000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3640 - accuracy: 0.3880 - val_loss: 1.3782 - val_accuracy: 0.5000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4451 - accuracy: 0.1739 - val_loss: 1.3852 - val_accuracy: 0.5000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4587 - accuracy: 0.1852 - val_loss: 1.3765 - val_accuracy: 0.5000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3788 - accuracy: 0.3205 - val_loss: 1.3709 - val_accuracy: 0.3750\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3561 - accuracy: 0.3655 - val_loss: 1.3898 - val_accuracy: 0.2500\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4697 - accuracy: 0.2536 - val_loss: 1.3807 - val_accuracy: 0.2500\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4382 - accuracy: 0.2522 - val_loss: 1.3783 - val_accuracy: 0.2500\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4054 - accuracy: 0.3023 - val_loss: 1.3680 - val_accuracy: 0.2500\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4223 - accuracy: 0.3427 - val_loss: 1.3673 - val_accuracy: 0.2500\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4382 - accuracy: 0.1988 - val_loss: 1.3564 - val_accuracy: 0.3750\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3500 - accuracy: 0.3363 - val_loss: 1.3444 - val_accuracy: 0.2500\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3701 - accuracy: 0.1981 - val_loss: 1.3388 - val_accuracy: 0.5000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3507 - accuracy: 0.3594 - val_loss: 1.3388 - val_accuracy: 0.3750\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4251 - accuracy: 0.3920 - val_loss: 1.3336 - val_accuracy: 0.5000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3277 - accuracy: 0.4388 - val_loss: 1.2788 - val_accuracy: 0.5000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4806 - accuracy: 0.2765 - val_loss: 1.3041 - val_accuracy: 0.5000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2668 - accuracy: 0.3783 - val_loss: 1.2990 - val_accuracy: 0.2500\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4419 - accuracy: 0.0956 - val_loss: 1.2598 - val_accuracy: 0.6250\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3679 - accuracy: 0.4498 - val_loss: 1.2865 - val_accuracy: 0.2500\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3032 - accuracy: 0.4889 - val_loss: 1.1542 - val_accuracy: 0.7500\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4529 - accuracy: 0.1640 - val_loss: 1.1528 - val_accuracy: 0.7500\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3967 - accuracy: 0.3375 - val_loss: 1.2001 - val_accuracy: 0.3750\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4074 - accuracy: 0.3216 - val_loss: 1.1531 - val_accuracy: 0.3750\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3360 - accuracy: 0.2729 - val_loss: 1.1521 - val_accuracy: 0.5000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4605 - accuracy: 0.2634 - val_loss: 1.1021 - val_accuracy: 0.5000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1965 - accuracy: 0.3077 - val_loss: 1.1085 - val_accuracy: 0.5000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.5042 - accuracy: 0.3749 - val_loss: 0.9997 - val_accuracy: 0.5000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0892 - accuracy: 0.6555 - val_loss: 1.0064 - val_accuracy: 0.5000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1436 - accuracy: 0.5332 - val_loss: 0.9094 - val_accuracy: 0.5000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0395 - accuracy: 0.3324 - val_loss: 0.8643 - val_accuracy: 0.5000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9142 - accuracy: 0.5218 - val_loss: 0.8835 - val_accuracy: 0.5000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0796 - accuracy: 0.5816 - val_loss: 0.8379 - val_accuracy: 0.5000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1791 - accuracy: 0.4404 - val_loss: 0.9179 - val_accuracy: 0.6250\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.9452 - accuracy: 0.6037 - val_loss: 0.8049 - val_accuracy: 0.6250\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8509 - accuracy: 0.7027 - val_loss: 0.8485 - val_accuracy: 0.5000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9107 - accuracy: 0.7685 - val_loss: 0.8677 - val_accuracy: 0.7500\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9004 - accuracy: 0.6866 - val_loss: 0.7342 - val_accuracy: 0.5000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0768 - accuracy: 0.2819 - val_loss: 0.7094 - val_accuracy: 0.8750\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8899 - accuracy: 0.4238 - val_loss: 0.8232 - val_accuracy: 0.6250\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8291 - accuracy: 0.5877 - val_loss: 0.7205 - val_accuracy: 0.3750\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1283 - accuracy: 0.2447 - val_loss: 0.7952 - val_accuracy: 0.6250\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9176 - accuracy: 0.5131 - val_loss: 0.7752 - val_accuracy: 0.7500\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.8358 - accuracy: 0.5677 - val_loss: 0.7729 - val_accuracy: 0.5000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9721 - accuracy: 0.4768 - val_loss: 0.6330 - val_accuracy: 0.6250\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5822 - accuracy: 0.8308 - val_loss: 0.6485 - val_accuracy: 0.6250\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.9050 - accuracy: 0.4899 - val_loss: 0.7912 - val_accuracy: 0.5000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7508 - accuracy: 0.5807 - val_loss: 0.6265 - val_accuracy: 0.7500\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7880 - accuracy: 0.5627 - val_loss: 0.6158 - val_accuracy: 0.7500\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7136 - accuracy: 0.6282 - val_loss: 0.5997 - val_accuracy: 0.6250\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7419 - accuracy: 0.6368 - val_loss: 0.6039 - val_accuracy: 0.7500\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7628 - accuracy: 0.5503 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5133 - accuracy: 0.6921 - val_loss: 0.5773 - val_accuracy: 0.7500\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.7165 - val_loss: 0.4292 - val_accuracy: 0.8750\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7602 - accuracy: 0.6015 - val_loss: 0.5771 - val_accuracy: 0.6250\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7978 - accuracy: 0.4754 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7368 - accuracy: 0.7132 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.9737 - accuracy: 0.4891 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.8059 - accuracy: 0.5111 - val_loss: 0.4841 - val_accuracy: 0.7500\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6406 - accuracy: 0.7409 - val_loss: 0.5549 - val_accuracy: 0.7500\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7261 - accuracy: 0.4820 - val_loss: 0.5493 - val_accuracy: 0.6250\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7353 - accuracy: 0.5568 - val_loss: 0.4546 - val_accuracy: 0.7500\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6863 - accuracy: 0.6323 - val_loss: 0.4603 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.5485 - accuracy: 0.7616 - val_loss: 0.4772 - val_accuracy: 0.7500\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5825 - accuracy: 0.6687 - val_loss: 0.4377 - val_accuracy: 0.7500\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6016 - accuracy: 0.7309 - val_loss: 0.4354 - val_accuracy: 0.7500\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7243 - accuracy: 0.5462 - val_loss: 0.4318 - val_accuracy: 0.8750\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6294 - accuracy: 0.5377 - val_loss: 0.4030 - val_accuracy: 0.8750\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6914 - accuracy: 0.5719 - val_loss: 0.4527 - val_accuracy: 0.7500\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0016 - accuracy: 0.5585 - val_loss: 0.6039 - val_accuracy: 0.6250\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6287 - accuracy: 0.8642 - val_loss: 0.4242 - val_accuracy: 0.8750\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.7092 - val_loss: 0.4029 - val_accuracy: 0.7500\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5675 - accuracy: 0.7692 - val_loss: 0.4311 - val_accuracy: 0.6250\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6324 - accuracy: 0.7405 - val_loss: 0.4639 - val_accuracy: 0.7500\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4870 - accuracy: 0.8307 - val_loss: 0.4969 - val_accuracy: 0.6250\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5779 - accuracy: 0.7849 - val_loss: 0.4394 - val_accuracy: 0.8750\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5152 - accuracy: 0.6842 - val_loss: 0.4600 - val_accuracy: 0.7500\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6685 - accuracy: 0.7043 - val_loss: 0.3853 - val_accuracy: 0.8750\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.6006 - val_loss: 0.4544 - val_accuracy: 0.7500\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4828 - accuracy: 0.6453 - val_loss: 0.4408 - val_accuracy: 0.7500\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7651 - accuracy: 0.6423 - val_loss: 0.5114 - val_accuracy: 0.6250\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6106 - accuracy: 0.6107 - val_loss: 0.4368 - val_accuracy: 0.7500\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5520 - accuracy: 0.7141 - val_loss: 0.3567 - val_accuracy: 0.8750\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7154 - accuracy: 0.5614 - val_loss: 0.3944 - val_accuracy: 0.7500\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.5921 - val_loss: 0.4357 - val_accuracy: 0.6250\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5354 - accuracy: 0.6654 - val_loss: 0.3899 - val_accuracy: 0.7500\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5471 - accuracy: 0.7455 - val_loss: 0.3850 - val_accuracy: 0.7500\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5952 - accuracy: 0.6871 - val_loss: 0.4830 - val_accuracy: 0.7500\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6086 - accuracy: 0.6211 - val_loss: 0.3221 - val_accuracy: 0.8750\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8563 - val_loss: 0.5900 - val_accuracy: 0.6250\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5575 - accuracy: 0.8165 - val_loss: 0.4178 - val_accuracy: 0.7500\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6324 - accuracy: 0.6383 - val_loss: 0.4037 - val_accuracy: 0.7500\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.6920 - val_loss: 0.3975 - val_accuracy: 0.7500\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.6931 - val_loss: 0.3751 - val_accuracy: 0.7500\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.6521 - val_loss: 0.3742 - val_accuracy: 0.6250\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6016 - accuracy: 0.5047 - val_loss: 0.3749 - val_accuracy: 0.7500\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5347 - accuracy: 0.7428 - val_loss: 0.3621 - val_accuracy: 0.7500\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4640 - accuracy: 0.8557 - val_loss: 0.3550 - val_accuracy: 0.7500\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5698 - accuracy: 0.6487 - val_loss: 0.3828 - val_accuracy: 0.7500\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.7829 - val_loss: 0.4031 - val_accuracy: 0.7500\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.6133 - accuracy: 0.6898 - val_loss: 0.3798 - val_accuracy: 0.8750\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6066 - accuracy: 0.6822 - val_loss: 0.3493 - val_accuracy: 0.8750\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.7402 - val_loss: 0.3314 - val_accuracy: 0.6250\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4367 - accuracy: 0.7679 - val_loss: 0.3805 - val_accuracy: 0.7500\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2754 - accuracy: 0.9191 - val_loss: 0.3452 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7146 - accuracy: 0.6511 - val_loss: 0.3719 - val_accuracy: 0.8750\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.7338 - val_loss: 0.4000 - val_accuracy: 0.6250\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.4917 - accuracy: 0.6555 - val_loss: 0.3199 - val_accuracy: 0.8750\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5089 - accuracy: 0.6990 - val_loss: 0.3185 - val_accuracy: 0.8750\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7490 - accuracy: 0.5260 - val_loss: 0.3046 - val_accuracy: 0.8750\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3552 - accuracy: 0.9249 - val_loss: 0.3600 - val_accuracy: 0.7500\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3711 - accuracy: 0.8333 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6927 - accuracy: 0.5970 - val_loss: 0.3685 - val_accuracy: 0.8750\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4900 - accuracy: 0.7071 - val_loss: 0.3518 - val_accuracy: 0.8750\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.7296 - val_loss: 0.3316 - val_accuracy: 0.7500\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.2601 - accuracy: 0.8435 - val_loss: 0.3420 - val_accuracy: 0.8750\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3834 - accuracy: 0.8577 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7554 - accuracy: 0.6192 - val_loss: 0.3145 - val_accuracy: 0.8750\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4387 - accuracy: 0.7696 - val_loss: 0.3960 - val_accuracy: 0.7500\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5411 - accuracy: 0.7146 - val_loss: 0.3496 - val_accuracy: 0.8750\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3738 - accuracy: 0.7247 - val_loss: 0.3116 - val_accuracy: 0.8750\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7560 - accuracy: 0.5055 - val_loss: 0.3532 - val_accuracy: 0.8750\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5948 - accuracy: 0.6483 - val_loss: 0.3137 - val_accuracy: 0.8750\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4663 - accuracy: 0.7976 - val_loss: 0.3145 - val_accuracy: 0.8750\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4426 - accuracy: 0.7990 - val_loss: 0.3608 - val_accuracy: 0.8750\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3319 - accuracy: 0.7864 - val_loss: 0.3261 - val_accuracy: 0.8750\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.7571 - accuracy: 0.4852 - val_loss: 0.3372 - val_accuracy: 0.8750\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5182 - accuracy: 0.7640 - val_loss: 0.3387 - val_accuracy: 0.8750\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3712 - accuracy: 0.8761 - val_loss: 0.3570 - val_accuracy: 0.8750\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4224 - accuracy: 0.6731 - val_loss: 0.3143 - val_accuracy: 0.7500\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3728 - accuracy: 0.8470 - val_loss: 0.3418 - val_accuracy: 0.6250\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.7175 - val_loss: 0.3363 - val_accuracy: 0.8750\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8682 - val_loss: 0.2951 - val_accuracy: 0.8750\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.7857 - val_loss: 0.3468 - val_accuracy: 0.8750\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.7605 - accuracy: 0.6802 - val_loss: 0.3572 - val_accuracy: 0.8750\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5742 - accuracy: 0.6518 - val_loss: 0.3110 - val_accuracy: 0.7500\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3761 - accuracy: 0.7654 - val_loss: 0.3180 - val_accuracy: 0.8750\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.4094 - accuracy: 0.7238 - val_loss: 0.3978 - val_accuracy: 0.8750\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3104 - accuracy: 0.9053 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5507 - accuracy: 0.6599 - val_loss: 0.3999 - val_accuracy: 0.7500\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3001 - accuracy: 0.8705 - val_loss: 0.3133 - val_accuracy: 0.8750\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4932 - accuracy: 0.6243 - val_loss: 0.3321 - val_accuracy: 0.8750\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3036 - accuracy: 0.8732 - val_loss: 0.2889 - val_accuracy: 0.8750\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5687 - accuracy: 0.7772 - val_loss: 0.3413 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f906618dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcoLLlzMRBVM",
        "outputId": "da43eb48-913d-489d-d341-9cf0bb84bb45"
      },
      "source": [
        "#Model Evaluation\r\n",
        "model.evaluate_generator(generator=test_set, steps=200)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3081400394439697, 0.875]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKVSRpMJRDyH",
        "outputId": "19c3bd89-c037-47f9-a12a-75ad31de0aeb"
      },
      "source": [
        "#test veri setini değiştiriyoruz. Ama önce sıfırlanması gerekiyor\r\n",
        "test_set.reset()\r\n",
        "pred = model.predict_generator(test_set, verbose=1) #steps= len(test_set)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 5ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3FP2cWXRGGL"
      },
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)\r\n",
        "#print(predicted_class_indices)\r\n",
        "\r\n",
        "labels = (training_set.class_indices)\r\n",
        "labels = dict((v,k) for k,v in labels.items())\r\n",
        "predictions = [labels[k] for k in predicted_class_indices]\r\n",
        "predictions = predictions[:600]\r\n",
        "filenames=test_set.filenames\r\n",
        "#print(filenames)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTyuCRKBRI4w",
        "outputId": "5e7a9a45-99f0-44a6-841b-b3a28d45030e"
      },
      "source": [
        "print(len(filenames), len(predictions))\r\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIBkHS1fp725"
      },
      "source": [
        "Karşılaştırmalar için tablo oluşturuldu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rly7xsQRMeS"
      },
      "source": [
        "import csv\r\n",
        "results=pd.DataFrame({\"Filename\" :filenames,\r\n",
        "                      \"Predictions\":predictions})\r\n",
        "\r\n",
        "    \r\n",
        "results.to_csv(\"prediction_results.csv\",index=False)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhuF-Th0tUAC"
      },
      "source": [
        "from keras.models import model_from_json\r\n",
        "\r\n",
        "#%% model save .json\r\n",
        "\r\n",
        "model_json = model.to_json()\r\n",
        "\r\n",
        "with open(\"drive/My Drive/voice_analysis.json\", \"w\") as json_file:\r\n",
        "    json_file.write(model_json)\r\n",
        "\r\n",
        "# serialize weights to HDF5\r\n",
        "model.save_weights(\"drive/My Drive/voice_analysis.h5\")\r\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1PK8IuSvwWw"
      },
      "source": [
        "Eğitilmiş Ağ kaydediliyor ve yükleniyor.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9RixMOWsgSc"
      },
      "source": [
        "json_file = open('drive/My Drive/voice_analysis.json', 'r')\r\n",
        "loaded_model_json = json_file.read()\r\n",
        "json_file.close()\r\n",
        "loaded_model = model_from_json(loaded_model_json)\r\n",
        "\r\n",
        "loaded_model.load_weights(\"drive/My Drive/voice_analysis.h5\")\r\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bcr3GeryRZR"
      },
      "source": [
        "Farklı kişi sesleriyle eğitilmiş ağ test ediliyor. (Doğruluk değerinin azalması beklenir. Ses tanıma kişiye özeldir.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNQXJ9NxxQK",
        "outputId": "3088f71f-0ad6-44a0-fc13-31a072059314"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory(\r\n",
        "    'test_png',   # 'test_png'-> './data2/val' for another people same words\r\n",
        "    target_size=(64, 64),    ## input size belirlendi.\r\n",
        "    batch_size=1,\r\n",
        "    class_mode='binary',\r\n",
        "    shuffle = False )"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfYoCZA3wDjL",
        "outputId": "4f026448-47b9-4f6a-8bf7-255d305a088a"
      },
      "source": [
        "#Egitime yuklenen ag ile deneme\r\n",
        "from keras.models import model_from_json\r\n",
        "\r\n",
        "loaded_model_predict = loaded_model.predict(test_set)\r\n",
        "model = model_from_json(loaded_model_json)\r\n",
        "#load weights into new model\r\n",
        "model.load_weights(\"drive/My Drive/voice_analysis.h5\")\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\r\n",
        "                                                \r\n",
        "\r\n",
        "y_final_oneHotEncoded= model.predict_classes(test_set, batch_size=1, verbose=0)  \r\n",
        "predictNumber = y_final_oneHotEncoded[0]\r\n",
        "words=['down', 'eat', 'sleep', 'up']\r\n",
        "\r\n",
        "temp=0\r\n",
        "for i in range (len(y_final_oneHotEncoded)):\r\n",
        "  original = test_set.filenames[i]\r\n",
        "  predict =  words[y_final_oneHotEncoded[i]]\r\n",
        "\r\n",
        "  if i<10:\r\n",
        "    orig = \"down\"\r\n",
        "  elif i<20:\r\n",
        "    orig= \"eat\"\r\n",
        "  elif i<30:\r\n",
        "    orig= \"sleep\"\r\n",
        "  else:\r\n",
        "    orig= \"up\"\r\n",
        "\r\n",
        "  print(\"original:\" , orig ,\" \", original )\r\n",
        "  print(\"prediction:\" , predict)\r\n",
        "\r\n",
        "  if orig == predict :\r\n",
        "    temp = temp+1\r\n",
        "    print(\"true\")\r\n",
        "  else:\r\n",
        "    print(\"wrong\")\r\n",
        "\r\n",
        "\r\n",
        " \r\n",
        "print(\"acc:\", temp / 40)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original: down   down/down-1.png\n",
            "prediction: up\n",
            "wrong\n",
            "original: down   down/down-10.png\n",
            "prediction: sleep\n",
            "wrong\n",
            "original: down   down/down-2.png\n",
            "prediction: sleep\n",
            "wrong\n",
            "original: down   down/down-3.png\n",
            "prediction: down\n",
            "true\n",
            "original: down   down/down-4.png\n",
            "prediction: eat\n",
            "wrong\n",
            "original: down   down/down-5.png\n",
            "prediction: up\n",
            "wrong\n",
            "original: down   down/down-6.png\n",
            "prediction: up\n",
            "wrong\n",
            "original: down   down/down-7.png\n",
            "prediction: sleep\n",
            "wrong\n",
            "original: down   down/down-8.png\n",
            "prediction: sleep\n",
            "wrong\n",
            "original: down   down/down-9.png\n",
            "prediction: sleep\n",
            "wrong\n",
            "original: eat   eat/eat-1.png\n",
            "prediction: eat\n",
            "true\n",
            "original: eat   eat/eat-10.png\n",
            "prediction: eat\n",
            "true\n",
            "original: eat   eat/eat-2.png\n",
            "prediction: sleep\n",
            "wrong\n",
            "original: eat   eat/eat-3.png\n",
            "prediction: eat\n",
            "true\n",
            "original: eat   eat/eat-4.png\n",
            "prediction: eat\n",
            "true\n",
            "original: eat   eat/eat-5.png\n",
            "prediction: down\n",
            "wrong\n",
            "original: eat   eat/eat-6.png\n",
            "prediction: eat\n",
            "true\n",
            "original: eat   eat/eat-7.png\n",
            "prediction: eat\n",
            "true\n",
            "original: eat   eat/eat-8.png\n",
            "prediction: eat\n",
            "true\n",
            "original: eat   eat/eat-9.png\n",
            "prediction: eat\n",
            "true\n",
            "original: sleep   sleep/sleep-1.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-10.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-2.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-3.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-4.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-5.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-6.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-7.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-8.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: sleep   sleep/sleep-9.png\n",
            "prediction: sleep\n",
            "true\n",
            "original: up   up/up-1.png\n",
            "prediction: down\n",
            "wrong\n",
            "original: up   up/up-10.png\n",
            "prediction: down\n",
            "wrong\n",
            "original: up   up/up-2.png\n",
            "prediction: up\n",
            "true\n",
            "original: up   up/up-3.png\n",
            "prediction: down\n",
            "wrong\n",
            "original: up   up/up-4.png\n",
            "prediction: up\n",
            "true\n",
            "original: up   up/up-5.png\n",
            "prediction: sleep\n",
            "wrong\n",
            "original: up   up/up-6.png\n",
            "prediction: down\n",
            "wrong\n",
            "original: up   up/up-7.png\n",
            "prediction: up\n",
            "true\n",
            "original: up   up/up-8.png\n",
            "prediction: up\n",
            "true\n",
            "original: up   up/up-9.png\n",
            "prediction: up\n",
            "true\n",
            "acc: 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}